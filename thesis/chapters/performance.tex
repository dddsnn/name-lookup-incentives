\chapter{Performance}
\label{chap:performance}
One of the requirements of the system is to provide name resolution with a
latency low enough to be useful for real-time interaction, e.g. in the chat
system given as an example in the introduction.

The central performance characteristic to consider is the total latency of a
query a peer sends. It is dependent on a number of factors:

\begin{itemize}
\item The distance of the peer's routing prefix to the target ID (in the extreme
case, the peer is responsible for the target ID himself and can resolve the
query locally).
\item The network delay between the peers involved in the query chain.
\item The length of the routing prefix. The longer it is, the higher the average
number of recursive steps necessary for a resolution.
\item The subprefix coverage of all involved peers. The more peers there are per
subprefix, the higher the chance that a step in the query chance can be skipped
(by being able to select a peer who is not just one bit closer to the target ID,
but two, or even more). If the subprefix coverage is incomplete at some steps,
the query may not be resolvable at all without violating the rule that a query
recipient must be closer to the target ID.
\item The reputation of the involved peers in their query groups. Firstly, this
determines whether a penalty delay will be applied, but if a recipient is
reputation saturated, he will let the query time out.
\item Whether only one or multiple queries are sent. When sending more than one,
the probability that both fail or time out is lower than if only one is sent.
\end{itemize}

\section{Theoretical Latency}
The system has not been fully implemented, so it is not possible to measure
latencies from a real system. But theoretical considerations can be done. A good
starting point is to be optimistic about the factors influencing latency.

\paragraph{Simple Case}
Assume the following:

\begin{itemize}
\item The network round-trip time between any two peers is
$t_{RTT}$\footnote{Of course it's very unrealistic to assume it's the same for
any pair of peers. But it's useful as a first approximation to make statements
about expected query times.}.
\item The routing prefix is $l_{r}$ bits long.
\item Every peer in the network has complete subprefix coverage and knows
exactly $n_{qp}$ query peers for every subprefix.
\item All peers are above the penalty threshold reputation in all query groups,
but none are saturated.
\item Peers only send one query at time.
\item Local lookups are instantaneous.
\item There are no packet drops of failures in the network.
\item Connections between query peers are already set up, no need for
handshakes.
\item Peer IDs are equally distributed.
\end{itemize}

If a query is sent under these circumstances, all peers will be cooperative and
no penalty delays will be imposed.

Now suppose a query is sent for a target ID $ID_{target}$ that is $k$ steps away
from the querying peer's routing prefix $r$, i.e. $l_{r} - o(ID_{target}, r) =
k$. At every but the last step in the query chain, a peer has to be selected to
forward the query to. Suppose the selected peer's routing prefix is exactly one
bit closer to the target ID. Then the query will take $k \cdot t_{RTT}$.

\paragraph{Skipping Steps}
Now consider that, out of the $n_{qp}$ query peers each peer in the query chain
has to choose from to forward the query to, some may be more than one step
closer to the target ID. Thus it may be possible to, for example, forward the
query to a peer two steps closer, skipping one step in the query chain. The
probability to be able to skip at least $n_{skip}$ steps is $1 - (1 -
2^{-n_{skip}})^{n_{qp}}$ (assuming, of course, that there even are that many
steps left).

To get the expected value $E(n_{qp})$ of steps that can be skipped given a
number of query peers, set this probability to 0.5. Solving for $n_{skip}$
yields

\[E(n_{qp}) = n_{skip} = \log_2\left(\frac{1}{1 -
0.5^{\frac{1}{n_{qp}}}}\right).\]

So for example, with 4 query peers, the expected number of steps that can be
skipped by selecting the right peer is about 2.65. To be precise of course, this
has to be capped by the distance to the target ID.

Taking this into account, the expected query time drops to $\lceil\frac{k}{1 +
E(n_{qp})}\rceil \cdot t_{RTT}$.

\paragraph{Timeouts}
Responses can time out if the recipient of a query is reputation saturated, or
is unable to resolve the query in the required time. Let $p_{timeout}$ be the
probability that a query times out, and let $t_{timeout}$ be the time after
which peers consider a query timed out. Further assume that timeouts can happen
independently at any point in a query chain.

Since we're assuming $t_{timeout}$ to be the same for all peers, one timeout
means the query times out at every step and has to be retried from scratch. For
a query to be successful, there must be no timeouts at any of the hops. The
number of hops $n_{hops}$ has been estimated as $\lceil\frac{k}{1 +
E(n_{qp})}\rceil$ above. The probability that a query is successful $p_{qs}$
equals the probability that there is no timeout at any hop. So $p_{qs} = (1 -
p_{timeout})^{n_{hops}}$.

Let $n_{retry}$ be the number of times the peer who started the query will retry
it. Assume that the retries are independent of the queries coming
before it.

There is of course the possibility that all tries fail, which is $p_{fail} = (1
- p_{qs})^{n_{retry} + 1}$.

If the query ends up being successful within that number of retries,
the expected query time is
\[\frac{\sum_{i = 0}^{n_{retry}}p_{qs} \cdot (1 - p_{qs})^i \cdot (n_{hops}
\cdot t_{RTT} + i \cdot t_{timeout})}{1 - p_{fail}}.\]

\paragraph{Concrete Values}
Plugging in some roughly realistic values for the variables to get a feel for
the kind of latency the DHT has.

Set $t_{RTT} = \SI{50}{\milli\second}$, and $n_{qp} = 3$. Set the length of the
routing prefix $l_r = 16$. Supposing a network of $2^{22}$, or about 4 million,
peers, this implies average sync group sizes of 64 peers.

In the simple case where no steps are skipped, a query that has to go the full
$l_r$ steps (i.e. where the querying peer has no overlap with the target ID)
takes $16 \cdot \SI{50}{\milli\second} = \SI{800}{\milli\second}$.

If we do consider skipping steps, the average query time drops to
$\lceil\frac{16}{1 + E(3)}\rceil \cdot \SI{50}{\milli\second} =
\SI{250}{\milli\second}$.

Considering now that queries can time out with probability $p_{timeout} = 1\%$,
the timeout triggers after $t_{timeout} = \SI{2000}{\milli\second}$ and peers
retry $n_{retry} = 2$ times, the expected query time is
$\SI{352}{\milli\second}$.

\section{Simulated Performance}
A simulation was executed for 200 seconds with mostly default settings, except
that there are 256 peers, the routing prefix length is 6 bits, and the network
delay is $\SI{50}{\milli\second}$\footnote{A longer routing prefix is sadly not
possible without adding many more peers, which would take long and a lot of
memory to simulate.}. The total time taken of successful queries is examined
(this includes queries that timed out or failed, but were successfully retried).

Disregarding the first 100 seconds to let the peers gain reputation, the
performance is quite good. The median response time is
$\SI{100}{\milli\second}$ (one RTT), the 75th percentile
$\SI{200}{\milli\second}$, the 95th $\SI{300}{\milli\second}$. Out of 25693
successful queries, 13593 took one RTT, 10525 took two, 730 took three RTTs.
Only 794 took over one second. There were apparently some long running queries
from peers with no reputation: The maximum time was 22.2 seconds. These likely
had a significant impact on the fairly high mean time of
$\SI{239}{\milli\second}$.

These times are not representative of the query times in a large networks, since
the routing prefix is so short; very often, only one hop is necessary. More hops
make failures more likely and increase the average query times.

\section{Comparison with Plain DNS}
The obvious first candidate to compare against is plain DNS, the privacy issues
of which the system described in this thesis is designed to address.

DNS has a hierarchical namespace, in contrast to the flat namespace of the DHT.
However, the tree generated by the parts of domain names is similar to the
routing tree of the DHT. And in fact, their respective depths principally
influence the number of hops a query has to take, to other name servers or other
nodes in the DHT.

Of course this disregards the existence of caching, which can greatly speed up
DNS queries, as well as the fact that the name server for a subdomain may be
very close or even be the same machine.

Measuring DNS performance in real systems is
difficult~\cite{liston2002diversity}. Ager et al.\cite{ager2010comparing}
examined DNS response times from real-world vantage points and found times
ranging from 10 milliseconds all the way up to 5 seconds, although with the
lower end of that spectrum being much more likely. It seems fair to say a
typical DNS query takes on the order of a few tens of milliseconds. In direct
comparison, DNS queries are much faster than DHT lookups.

But they are not exactly comparable in purpose. The intended use case for DNS is
for a large number of users to be able to contact a relatively smaller number of
servers. The DHT in contrast stores reachability information for every peer. If
DNS did that, more records would need to be stored. Domain names may become
longer, meaning more hops and thereby longer query times, and caching may become
less effective.

\section{Comparison with a Simple Proxy}
A simple extension of just using DNS is using a simple proxy for DNS lookups.
This can provide some privacy protection by making profile building more
difficult. There are two ways for it: either there are a lot of other users
using the proxy for DNS lookups at the same DNS server. Their traffic can then
act as cover traffic. Alternatively, proxies can be switched often to "reset"
the data that has been accumulated.

Performance-wise, this should behave similar to plain DNS with the added
round-trip time to the proxy server (provided the proxy is fast enough and has
access to a similarly fast DNS server). This would very likely still be faster
than the DHT.

\section{Comparison with Tor}
When talking about privacy-enhancing technology, a comparison with Tor is
basically mandatory. Of course, Tor is a much stronger tool that aims to fully
anonymize all TCP traffic, not just make it less practical to collect data for
one particular service. It can be used just to anonymize DNS, though.

If the user wants to use Tor for anonymization anyway, a separate DNS lookup is
not even necessary. He just specifies the domain name of the target and the exit
node does the lookup.

Alternatively, Tor has a remote hostname lookup which instructs the exit node to
resolve a domain name and send back the A or AAAA record. However, this uses a
simple format rather than forwarding the DNS server response. It doesn't include
any DNSSEC records, so the user has to trust the exit node to send the correct
response.

If we stick to a very simplified view for a look at the performance, DNS queries
via Tor essentially add the round-trip times between the three Tor nodes to the
time the DNS query takes.

As for real-world data, the Tor Project measures various performance indicators
on its website\cite{torperf}, among them the circuit RTTs of an HTTP request.
This can reasonably be used as the time that would be added to the time of the
DNS lookup.

There are multiple graphs, presumably from different vantage points (the
documentation isn't clear on this). They differ quite a bit, but the median RTT
is always in the hundreds of milliseconds (from about $\SI{250}{\milli\second}$
to about $\SI{600}{\milli\second}$)\footnote{Figure~\ref{fig:tor_rtt} in the
appendix shows these graphs.}. The DNS query time that has to be added on top of
that is relatively insignificant.

Unsurprisingly, this is probably more than a single proxy server would add. If
the goal is really just to prevent profile building at the DNS server, using Tor
has no advantage over a proxy server. But the proxy would have to be switched
regularly to prevent profile building there. Tor has the advantage that new
circuits are created automatically, and that exit nodes can't build profiles
even if they are reused.

In comparison with the DHT, the DHT should actually come out ahead of Tor at
least at the slower Tor vantage points. The comparison to the faster vantage
points is more even.
